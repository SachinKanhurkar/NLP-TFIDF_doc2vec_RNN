{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare NLP Techniques: Build Model On word2vec Vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In Cleaned Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label   \n",
       "0   ham  \\\n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data and clean up column names\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "messages = pd.read_csv('../../../data/spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "messages.columns = [\"label\", \"text\"]\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[dun, say, so, early, hor, already, then, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, don, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label   \n",
       "0   ham  \\\n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text   \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \\\n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            text_clean  \n",
       "0  [go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...  \n",
       "1                                                                          [ok, lar, joking, wif, oni]  \n",
       "2  [free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...  \n",
       "3                                                       [dun, say, so, early, hor, already, then, say]  \n",
       "4                                [nah, don, think, he, goes, to, usf, he, lives, around, here, though]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data using the built in cleaner in gensim\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the label column\n",
    "messages['label']=messages['label'].map({'ham':1,'spam':0})\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split (messages['text_clean'], messages['label'] , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "646     1\n",
       "3859    1\n",
       "2643    1\n",
       "5331    1\n",
       "709     0\n",
       "       ..\n",
       "3521    1\n",
       "5495    1\n",
       "329     1\n",
       "3306    1\n",
       "3472    1\n",
       "Name: label, Length: 1115, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word2vec Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the word2vec model\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fuck', 0.9879058599472046),\n",
       " ('make', 0.9878668785095215),\n",
       " ('tell', 0.9876595139503479),\n",
       " ('babe', 0.9876301884651184),\n",
       " ('unsubscribe', 0.9876028299331665),\n",
       " ('last', 0.9875856637954712),\n",
       " ('need', 0.9875347018241882),\n",
       " ('as', 0.9875059723854065),\n",
       " ('didn', 0.9874580502510071),\n",
       " ('finally', 0.9874293804168701)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the most similar words to \"king\" based on word vectors from our trained model\n",
    "w2v_model.wv.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(w2v_model.wv.index_to_key)\n",
    "X_train_vect = np.array([np.mean([w2v_model.wv[i] for i in ls if i in words], axis=0)\n",
    "                         if len([i for i in ls if i in words]) > 0\n",
    "                         else np.zeros(w2v_model.vector_size)\n",
    "                         for ls in X_train])\n",
    "X_test_vect = np.array([np.mean([w2v_model.wv[i] for i in ls if i in words], axis=0)\n",
    "                         if len([i for i in ls if i in words]) > 0\n",
    "                         else np.zeros(w2v_model.vector_size)\n",
    "                         for ls in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1379898 ,  0.30345789,  0.08002605, ..., -0.32526428,\n",
       "         0.1298307 , -0.1111047 ],\n",
       "       [-0.18580902,  0.40065333,  0.10245626, ..., -0.43599811,\n",
       "         0.16912405, -0.15236582],\n",
       "       [-0.15680124,  0.34029946,  0.08536308, ..., -0.3679474 ,\n",
       "         0.14330894, -0.12657416],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.22458875,  0.44936523,  0.14282233, ..., -0.49510252,\n",
       "         0.21083243, -0.15327717],\n",
       "       [-0.14549118,  0.30408415,  0.08300597, ..., -0.3312577 ,\n",
       "         0.13461675, -0.11248601]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.37989804e-01,  3.03457886e-01,  8.00260529e-02,  9.81569886e-02,\n",
       "        1.02108583e-01, -5.25503039e-01,  2.69987345e-01,  6.78740084e-01,\n",
       "       -3.36819261e-01, -2.32861653e-01, -1.64803624e-01, -4.65315521e-01,\n",
       "       -5.48042022e-02,  9.04158279e-02,  1.64244980e-01, -2.42927864e-01,\n",
       "        6.73984215e-02, -4.13614988e-01,  1.45000883e-03, -5.68342328e-01,\n",
       "        1.64556950e-01,  4.45453450e-02,  2.31211200e-01, -2.25041971e-01,\n",
       "       -1.40416950e-01,  7.61006922e-02, -3.62688631e-01, -1.16342537e-01,\n",
       "       -1.81547865e-01,  8.45461264e-02,  3.27828497e-01, -8.95109698e-02,\n",
       "        1.31067485e-01, -2.16266006e-01, -9.00142342e-02,  3.41562927e-01,\n",
       "        6.25119954e-02, -1.66623235e-01, -1.77214310e-01, -4.93053019e-01,\n",
       "        1.48656920e-01, -3.22483927e-01, -2.04732567e-01,  9.80710029e-04,\n",
       "        2.75866896e-01, -1.03654303e-01, -2.88018554e-01,  2.10054349e-02,\n",
       "        2.22932026e-01,  1.51610151e-01,  1.57469153e-01, -2.91062295e-01,\n",
       "       -5.79073210e-04, -6.96066171e-02, -1.26138464e-01,  2.47210845e-01,\n",
       "        2.04106614e-01,  4.12421413e-02, -2.72288054e-01,  1.74480185e-01,\n",
       "        1.45101463e-02,  8.20779577e-02, -6.10372797e-02, -1.25638053e-01,\n",
       "       -2.70005316e-01,  3.07540834e-01,  1.78685665e-01,  3.18975300e-01,\n",
       "       -4.61358517e-01,  2.90825695e-01, -1.89736500e-01,  1.35237888e-01,\n",
       "        2.97642678e-01, -3.47827077e-02,  3.24451625e-01,  1.08449467e-01,\n",
       "        3.36420573e-02,  2.20149402e-02, -2.50725806e-01,  5.28042428e-02,\n",
       "       -2.33019322e-01, -9.10415407e-03, -2.51250684e-01,  4.21927541e-01,\n",
       "       -6.85852766e-02,  7.83565044e-02,  1.12741567e-01,  2.91344404e-01,\n",
       "        3.47367078e-01,  1.03096306e-01,  3.90300333e-01,  1.90388188e-01,\n",
       "        3.29030678e-02,  5.09356074e-02,  4.52233106e-01,  2.58093178e-01,\n",
       "        1.50233388e-01, -3.25264275e-01,  1.29830703e-01, -1.11104704e-01])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does the unaveraged version look like?\n",
    "X_train_vect[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit RandomForestClassifier On Top Of Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit a basic Random Forest model on top of the vectors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train_vect, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to make predictions on the test data\n",
    "y_pred = rf_model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.97 / Recall: 0.988 / Accuracy: 0.963\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions of the model on the holdout test set\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
